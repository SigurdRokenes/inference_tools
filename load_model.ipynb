{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this to load Tensorflow modelzoo models from export to run inference and inspect predictions.\n",
    "\n",
    "First some imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import matplotlib\n",
    "from matplotlib import patches, text, patheffects\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import cv2\n",
    "from src.image_tools import ImageTools\n",
    "import sys\n",
    "import random\n",
    "import colorsys\n",
    "import json\n",
    "\n",
    "try:\n",
    "    # Disable all GPUS\n",
    "    tf.config.set_visible_devices([], 'GPU')\n",
    "    visible_devices = tf.config.get_visible_devices()\n",
    "    for device in visible_devices:\n",
    "        assert device.device_type != 'GPU'\n",
    "except:\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass\n",
    "#physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "#if len(physical_devices) > 0:\n",
    "#    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "#from absl import app, flags, logging\n",
    "#from absl.flags import FLAGS\n",
    "import core.utils as utils\n",
    "from core.config import cfg\n",
    "from core.yolov4 import filter_boxes\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Not used\n",
    "THRESHOLD = 0.1\n",
    "YOLO = False\n",
    "#MODEL_PATH = 'trained_models/faster_rcnn/saved_model'\n",
    "MODEL_PATH = 'trained_models/efficientDet_d1/saved_model'\n",
    "#MODEL_PATH = 'trained_models/yolov4_1024'\n",
    "#MODEL_PATH = 'trained_models/faster_rcnn_5ksteps_dropout5/saved_model'\n",
    "#IMAGE_PATH = \"C:/Users/Sigurd/OneDriveMS/FYS-3741-MASTER/data/data_yoloformat/test/images\"\n",
    "#IMAGE_PATH = \"C:/Users/sigur/OneDriveMS/FYS-3741-MASTER/data/data_yoloformat/test/images\"\n",
    "IMAGE_PATH = \"C:/Users/Sigurd/OneDriveMS/FYS-3741-MASTER/Tensorflow/workspace/inference_tools/examples/test_im\"\n",
    "#IMAGE_PATH = \"C:/Users/sigur/OneDriveMS/FYS-3741-MASTER/Tensorflow/workspace/inference_tools/examples/test_im\"\n",
    "PLOT = True\n",
    "WRITE_TO_FILE = False\n",
    "#RESULT_PATH = \"New_labels/Frcnn_dropout.json\"\n",
    "RESULT_PATH = \"New_labels/EffDetD1_nms.json\"\n",
    "#INPUT_SIZE = 1024\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bbox(image, bboxes, classes=\"Porpoise\", show_label=True):\n",
    "    num_classes = 1\n",
    "    image_h, image_w, _ = image.shape\n",
    "    hsv_tuples = [(1.0 * x / num_classes, 1., 1.) for x in range(num_classes)]\n",
    "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "    colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
    "\n",
    "    random.seed(0)\n",
    "    random.shuffle(colors)\n",
    "    random.seed(None)\n",
    "\n",
    "    out_boxes, out_scores, out_classes, num_boxes = bboxes\n",
    "    #print(num_boxes)\n",
    "    for i in range(num_boxes):\n",
    "        if int(out_classes[i]) < 0 or int(out_classes[i]) > num_classes: continue\n",
    "        coor = out_boxes[i]\n",
    "        coor[0] = int(coor[0] * image_h)\n",
    "        coor[2] = int(coor[2] * image_h)\n",
    "        coor[1] = int(coor[1] * image_w)\n",
    "        coor[3] = int(coor[3] * image_w)\n",
    "        #### fontscale = 0.5\n",
    "        fontScale = 1\n",
    "        score = out_scores[i]\n",
    "        class_ind = int(out_classes[i])\n",
    "        class_name = classes\n",
    "        # check if class is in allowed classes\n",
    "\n",
    "        bbox_color = colors[0]\n",
    "        bbox_thick = int(0.6 * (image_h + image_w) / 600)\n",
    "        c1, c2 = (coor[1], coor[0]), (coor[3], coor[2])\n",
    "        cv2.rectangle(image, c1, c2, bbox_color, bbox_thick)\n",
    "        \n",
    "        if show_label:\n",
    "            bbox_mess = '%s: %.2f' % (\"Porpoise\", score)\n",
    "            t_size = cv2.getTextSize(bbox_mess, 0, fontScale, thickness=bbox_thick // 2)[0]\n",
    "            c3 = (c1[0] + t_size[0], c1[1] - t_size[1] - 3)\n",
    "            cv2.rectangle(image, c1, (np.float32(c3[0]), np.float32(c3[1])), bbox_color, -1) #filled\n",
    "\n",
    "            cv2.putText(image, bbox_mess, (c1[0], np.float32(c1[1] - 2)), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        fontScale, (0, 0, 0), bbox_thick // 2, lineType=cv2.LINE_AA)\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_image_to_numpy_array(path):\n",
    "    \"\"\"\n",
    "    Load a single image to numpy array\n",
    "    \"\"\"\n",
    "    img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
    "    image = Image.open(io.BytesIO(img_data))\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape(im_height, im_width, 3).astype(np.uint8)\n",
    "\n",
    "def convert_bb(bbox, img_shape):\n",
    "    \"\"\"\n",
    "    Convert bounding box coordinates from (ymin, xmin, ymax, xmax) to absolute form (xmin, ymin, w, h)\n",
    "    for use in evaluate_model2.ipynb\n",
    "    \"\"\"\n",
    "    boxes = np.zeros(bbox.shape)\n",
    "\n",
    "\n",
    "    boxes[:,0] = np.round((bbox[:,1])*img_shape[1],0)\n",
    "\n",
    "\n",
    "    boxes[:,1] = np.round(bbox[:,0]*img_shape[0],0)\n",
    "    boxes[:,2] = np.round(((bbox[:,3] - bbox[:,1])* img_shape[1]),0)\n",
    "\n",
    "    boxes[:,3] = np.round(((bbox[:,2] - bbox[:,0]) * img_shape[0]),0)\n",
    "    #print(boxes[:,3])\n",
    "\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model from file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_121105) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_108162) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_86331) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_125958) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_call_func_25631) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_84227) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_113015) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model in: 129.7710840702057 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "tf.keras.backend.clear_session()\n",
    "#Loads model\n",
    "detect_fn = tf.saved_model.load(MODEL_PATH)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Loaded model in: {} seconds'.format(elapsed_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run inference on model. Change plot to True if plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Images:\n",
      " Image: 2, Completion: 22%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sigurd\\AppData\\Local\\Temp\\ipykernel_19604\\944860231.py:31: DeprecationWarning: an integer is required (got type numpy.float32).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  cv2.rectangle(image, c1, c2, bbox_color, bbox_thick)\n",
      "C:\\Users\\Sigurd\\AppData\\Local\\Temp\\ipykernel_19604\\944860231.py:37: DeprecationWarning: an integer is required (got type numpy.float32).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  cv2.rectangle(image, c1, (np.float32(c3[0]), np.float32(c3[1])), bbox_color, -1) #filled\n",
      "C:\\Users\\Sigurd\\AppData\\Local\\Temp\\ipykernel_19604\\944860231.py:39: DeprecationWarning: an integer is required (got type numpy.float32).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  cv2.putText(image, bbox_mess, (c1[0], np.float32(c1[1] - 2)), cv2.FONT_HERSHEY_SIMPLEX,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Image: 10, Completion: 111%\n",
      " Process complete in 20.9 seconds \n",
      "\n",
      "Writing to file...\n",
      "Writing to file complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#image_dir = 'C:/Users/Sigurd/OneDriveMS/FYS-3741-MASTER/data/data_yoloformat/test_images_for_programming/'\n",
    "images = os.listdir(IMAGE_PATH)\n",
    "#image_names = os.listdir(image_dir)\n",
    "iou = 0.5\n",
    "score = 0.1\n",
    "#json_result = []\n",
    "start_time = time.time()\n",
    "print('Processing Images:')\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "#STRIDES, ANCHORS, NUM_CLASS, XYSCALE = utils.load_config(FLAGS)\n",
    "input_size = 1024\n",
    "#images = FLAGS.images\n",
    "#print('output1: ', output)\n",
    "#if output != None:\n",
    "#    output = 'output/images/'+output\n",
    "# load model\n",
    "#print(images)\n",
    "#print('output: ', output)\n",
    "#saved_model_loaded = tf.saved_model.load('./models/yolov4_1024', tags=[tag_constants.SERVING])\n",
    "#saved_model_loaded = model\n",
    "# loop through images in list and run Yolov4 model on each\n",
    "def main():\n",
    "    json_result = []    \n",
    "    for count, im_path in enumerate(images, 1):\n",
    "\n",
    "        #if count != 2:\n",
    "        #    continue\n",
    "        sys.stdout.write('\\r Image: {}, Completion: {}%'.format(count+1, round((count+1) / len(images)*100)))\n",
    "        #print('count: ', count)\n",
    "        #print('im_path: ', im_path)\n",
    "        image_path = IMAGE_PATH+'/'+im_path\n",
    "\n",
    "        #print(image_path)\n",
    "        if YOLO:\n",
    "            original_image = cv2.imread(image_path)\n",
    "            \n",
    "            original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            image_data = cv2.resize(original_image, (input_size, input_size))\n",
    "            image_data = image_data / 255.\n",
    "\n",
    "        else:\n",
    "            original_image = cv2.imread(image_path)\n",
    "            \n",
    "            original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            #image_data = cv2.resize(original_image, (input_size, input_size))\n",
    "            image_data = original_image\n",
    "            #print(image_data.dtype)\n",
    "\n",
    "\n",
    "        images_data = []\n",
    "        for i in range(1):\n",
    "            images_data.append(image_data)\n",
    "        images_data = np.asarray(images_data).astype(np.uint8)\n",
    "\n",
    "        batch_data = tf.constant(images_data)\n",
    "\n",
    "        infer = detect_fn.signatures['serving_default']\n",
    "        pred_bbox = infer(batch_data)\n",
    "\n",
    "        boxes = pred_bbox['detection_boxes'][0]\n",
    "        pred_conf = pred_bbox['detection_scores'][0]\n",
    "        classes = pred_bbox['detection_classes'][0]\n",
    "\n",
    "\n",
    "        valid_pred = tf.image.non_max_suppression(\n",
    "            boxes = boxes,\n",
    "            scores = pred_conf,\n",
    "            max_output_size = 10,\n",
    "            iou_threshold = iou,\n",
    "            score_threshold = score\n",
    "        )\n",
    "\n",
    "        bbox = tf.gather(boxes, valid_pred).numpy()\n",
    "\n",
    "                    #bbox-coords    #confidence                             #class prediction                   #valid detections   \n",
    "        pred_bbox = [bbox, tf.gather(pred_conf, valid_pred).numpy(), tf.gather(classes, valid_pred).numpy(), np.array(bbox.shape[0])]\n",
    "\n",
    "        if PLOT:\n",
    "            image = draw_bbox(original_image, pred_bbox)\n",
    "\n",
    "            #cv2.imshow(im_path, image)\n",
    "\n",
    "            image = Image.fromarray(image.astype(np.uint8))\n",
    "            \n",
    "\n",
    "            image.show(title='im_path')\n",
    "            #cv2.waitKey(0)\n",
    "            #cv2.destroyAllWindows()\n",
    "\n",
    "        if WRITE_TO_FILE:\n",
    "            if len(bbox)==0:\n",
    "                bbox_abs = []\n",
    "            else:\n",
    "                bbox_abs = convert_bb(bbox, image_data.shape)\n",
    "\n",
    "\n",
    "            for i in range(pred_bbox[3]):\n",
    "                json_result.append({\n",
    "                    \"image_id\": im_path,\n",
    "                    \"category_id\": int(pred_bbox[2][i]),\n",
    "                    \"bbox\": bbox_abs[i],\n",
    "                    \"score\": pred_bbox[1][i]\n",
    "                })\n",
    "        sys.stdout.flush()\n",
    "\n",
    "\n",
    "\n",
    "    end_time = time.time()\n",
    "    print('\\n','Process complete in {} seconds \\n'.format(round(end_time - start_time, 1)))\n",
    "\n",
    "    print('Writing to file...' )\n",
    "    if WRITE_TO_FILE:\n",
    "\n",
    "        #print(len(json_result))\n",
    "        with open('{}'.format(RESULT_PATH), 'w') as outfile:\n",
    "            outfile.write('[')\n",
    "            outfile.write('\\n')\n",
    "            for i in range(len(json_result)):\n",
    "                json.dump(str(json_result[i]), outfile, separators=(',', ':'))\n",
    "                if i < len(json_result) - 1:\n",
    "                    outfile.write(',\\n')\n",
    "                else:\n",
    "                    outfile.write('\\n')\n",
    "            outfile.write(']')\n",
    "\n",
    "    print('Writing to file complete.')\n",
    "\n",
    "main()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf925c25cf89ffabb2f3d88c1a5e71df6d5b95587e699ad6e5870eb2f2cce31d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
