{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "\n",
    "from src.image_tools import ImageTools\n",
    "from src.load_image import load_image_to_numpy_array\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paths and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "WORKING_DIR = \"C:/Users/Sigurd/OneDriveMS/FYS-3741-MASTER/\"\n",
    "GT_PATH = WORKING_DIR+\"data/data_yoloformat/test/annotations_1class/\"\n",
    "\n",
    "IMAGE_PATH = WORKING_DIR + \"data/data_yoloformat/test/images/\"\n",
    "#yolo\n",
    "PRED_PATH = WORKING_DIR+\"results/yolov4_testresults/1class/yolo_format/\"\n",
    "#PRED_PATH = WORKING_DIR+\"results/yolov4_testresults/annotations/absolute_format/\"\n",
    "#faster-rcnn\n",
    "#PRED_PATH = WORKING_DIR+\"results/fasterrcnn_testresults/yolo_format/\"\n",
    "#PRED_PATH = WORKING_DIR+\"results/efficientDet_testresults_0.1thresh/abs_format/\"\n",
    "#PRED_PATH = WORKING_DIR + 'results/fasterrcnn_testresults/yolo_format/'\n",
    "\n",
    "\n",
    "#WORKING_DIR = os.getcwd()\n",
    "\n",
    "\n",
    "#GT_PATH = \"examples/test_labels/\"\n",
    "GT = os.listdir(GT_PATH)\n",
    "#IMAGE_PATH = \"examples/test_im/\"\n",
    "IM = os.listdir(IMAGE_PATH)\n",
    "#PRED_PATH = \"examples/test_pred/\"\n",
    "PRED = os.listdir(PRED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class EvaluationTools:\n",
    "    def __init__(self, gt_path, im_path, pred_path, iou_threshold):\n",
    "        self.im_path = im_path\n",
    "        self.gt_path = gt_path\n",
    "        self.pred_path = pred_path\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.names = ['classification', 'x', 'y', 'w', 'h']\n",
    "        self.names_pred = ['classification', 'confidence', 'x', 'y', 'w', 'h']\n",
    "\n",
    "        self.im_w, self.im_h = self.get_image_info()\n",
    "\n",
    "\n",
    "    def get_bbox(self):\n",
    "        \"\"\"\n",
    "        Convert and return bonding box from path to pandas df (in x, y, h, w)\n",
    "        \"\"\"\n",
    "        gt = pd.read_csv(self.gt_path, sep = ' ', names = self.names, index_col = False)\n",
    "        \n",
    "        pred = pd.read_csv(self.pred_path, sep = ' ', header=None).drop(6, axis=1)\n",
    "        pred.columns = self.names_pred\n",
    "        #print('get bbox gt: ', gt)\n",
    "        return pred, self.yolo_to_absolute(gt)\n",
    "\n",
    "\n",
    "    def absolute_to_yolo(self, bbox):\n",
    "        \"\"\"\n",
    "        NOT USED\n",
    "        Convert bbox format from (xmin, ymin, w, h) to yolo\n",
    "        \"\"\"\n",
    "        n = (bbox.shape[0])\n",
    "        converted_bbox = bbox.copy()\n",
    "        for i in range(n):\n",
    "            converted_bbox['x'][i] = bbox['x'][i] / self.im_w\n",
    "            converted_bbox['y'][i] = bbox['y'][i] / self.im_h\n",
    "            converted_bbox['w'][i] = bbox['w'][i] / self.im_w\n",
    "            converted_bbox['h'][i] = bbox['h'][i] / self.im_h\n",
    "\n",
    "        return converted_bbox\n",
    "\n",
    "    def absolute_to_coordinates(self, bbox):\n",
    "        \"\"\"\n",
    "        convert bbox format from (xmin, ymin, w, h) to (xmin, ymin, xmax, ymax).\n",
    "        Param: bbox:\n",
    "                numpy array shape [n,4]\n",
    "        returns:\n",
    "                numpy array shape [n,4]\n",
    "        \"\"\"\n",
    "        converted_bbox = bbox.copy()\n",
    "        converted_bbox[:, 2] = bbox[:, 0] + bbox[:, 2]\n",
    "        converted_bbox[:, 3] = bbox[:, 1] + bbox[:, 3]\n",
    "\n",
    "        return converted_bbox\n",
    "\n",
    "    def yolo_to_absolute(self, bbox):\n",
    "        \"\"\"\n",
    "        Convert bbox format from yolo to (xmin, ymin, w, h)\n",
    "        \"\"\"\n",
    "        n = (bbox.shape[0])\n",
    "        converted_bbox = bbox.copy()\n",
    "        #print('yolo_to_absolute bbox: ', bbox)\n",
    "        for i in range(n):\n",
    "            converted_bbox['x'][i] = (bbox['x'][i] - 0.5*bbox['w'][i]) * self.im_w\n",
    "            converted_bbox['y'][i] = (bbox['y'][i] - 0.5*bbox['h'][i]) * self.im_h\n",
    "            converted_bbox['w'][i] = bbox['w'][i] * self.im_w\n",
    "            converted_bbox['h'][i] = bbox['h'][i] * self.im_h\n",
    "\n",
    "        return converted_bbox\n",
    "\n",
    "    def get_image_info(self):\n",
    "        \"\"\"\n",
    "        Fetch image height and width\n",
    "        \"\"\"\n",
    "        im = load_image_to_numpy_array(self.im_path)\n",
    "        im_w = im.shape[1]\n",
    "        im_h = im.shape[0]\n",
    "        return im_w, im_h\n",
    "    \n",
    "    def get_iou(self, pred, gt):\n",
    "        \"\"\"\n",
    "        Calculate intersection over union (IoU) between all bounding boxes in image.\n",
    "        Also calculates total pixel area of each bounding box\n",
    "\n",
    "        param:\n",
    "            \n",
    "        returns:\n",
    "        iou: float(0,1)\n",
    "        area_bb1: float\n",
    "        area_bb2: float\n",
    "        \"\"\"\n",
    "        #print('pred:', pred)\n",
    "        #print('gt: ',gt)\n",
    "        #remove values class/conf values and converte to coordinate form (pascalVOC)\n",
    "        bb1 = self.absolute_to_coordinates(np.array(pred)[:, 2:])\n",
    "        #print(bb1)\n",
    "        #add extra axis for calculation\n",
    "        bb1 = bb1[:, None]\n",
    "        #remove class value and convert to coordinate form (pascalVOC)\n",
    "        bb2 = self.absolute_to_coordinates(np.round(np.array(gt)[:, 1:], 0))\n",
    "        #print(bb2)\n",
    "        #print(bb1)\n",
    "        #print(bb2)\n",
    "        #calculation...\n",
    "        low = np.s_[...,:2]\n",
    "        high = np.s_[..., 2:]\n",
    "\n",
    "        bb1[high] += 1; bb2[high] += 1\n",
    "        \n",
    "        #intersect\n",
    "        intrs = (np.maximum(0,np.minimum(bb1[high],bb2[high])\n",
    "                            -np.maximum(bb1[low],bb2[low]))).prod(-1)\n",
    "        #iou\n",
    "        area_pred = (bb1[high]-bb1[low]).prod(-1)\n",
    "        area_gt = (bb2[high]-bb2[low]).prod(-1)\n",
    "        iou = intrs / (area_pred + area_gt -intrs + 1e-16)\n",
    "\n",
    "        return iou, area_gt\n",
    "    \n",
    "    def find_valid_detections(self, iou, iou_threshold, index_list):\n",
    "        \"\"\"\n",
    "        find number TP, FP, FN \n",
    "        \"\"\"\n",
    "        #print(iou)\n",
    "        #iou = np.zeros(iou_0.shape)\n",
    "        #print(iou.shape)\n",
    "        closest_box = np.max(iou, axis=1)\n",
    "        closest_gt = np.max(iou, axis=0)\n",
    "        valid_boxes = closest_box.copy()\n",
    "        valid_boxes[np.where(closest_box <= iou_threshold)] = 0\n",
    "        valid_gt = closest_gt.copy()\n",
    "        valid_gt[np.where(closest_gt <= iou_threshold)] = 0\n",
    "\n",
    "\n",
    "        tp = np.zeros(len(index_list)); fp = np.zeros(len(index_list)); fn = np.zeros(len(index_list))\n",
    "\n",
    "        for i in range(len(index_list)):\n",
    "            try:\n",
    "                tp[i] += np.count_nonzero(valid_boxes[index_list[i]])\n",
    "                fp[i] += closest_box[index_list[i]].shape[0] - np.count_nonzero(valid_boxes[index_list[i]])\n",
    "            except:\n",
    "                tp[i] += np.count_nonzero(valid_gt[index_list[i]])\n",
    "                fn[i] = closest_gt[index_list[i]].shape[0] - np.count_nonzero(valid_gt[index_list[i]])\n",
    "                 \n",
    "        return tp, fp, fn\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def number_of_detections(self, area_gt):\n",
    "\n",
    "        area = np.ravel(area_gt)\n",
    "        #print(area)\n",
    "        small_thresh = 32**2\n",
    "        med_thresh = 96**2\n",
    "        \n",
    "        index_full = np.full(area.shape, True)\n",
    "        index_small = np.full(area.shape, False)\n",
    "        index_med = np.full(area.shape, False)\n",
    "        index_large = np.full(area.shape, False)\n",
    "        \n",
    "        #print('index_small:', index_small)\n",
    "        \n",
    "        for i in range(area.shape[0]):\n",
    "           \n",
    "            if area[i] < small_thresh:\n",
    "                index_small[i] = True\n",
    "                #pred_small += 1\n",
    "            elif area[i] >= small_thresh and area[i] < med_thresh:\n",
    "                index_med[i] = True\n",
    "                #pred_med += 1\n",
    "            elif area[i] >= med_thresh:\n",
    "                index_large[i] = True\n",
    "                #pred_large += 1\n",
    "            else:\n",
    "                raise Exception('Value for bbox area is invalid')\n",
    "\n",
    "        #print('index_small post loop:', index_small)\n",
    "        #print([index_full, index_small, index_med, index_large])\n",
    "        return [index_full, index_small, index_med, index_large]\n",
    "\n",
    "    def no_predictions(self):\n",
    "        \"\"\"\n",
    "        Handles situations where there are no valid predictions for a ground truth. Every gt object will be a false negative.\n",
    "        \"\"\"\n",
    "        gt = pd.read_csv(self.gt_path, sep = ' ', names = self.names, index_col = False)\n",
    "        gt = self.yolo_to_absolute(gt)\n",
    "        low = np.s_[...,:2]\n",
    "        high = np.s_[..., 2:]\n",
    "        bb2 = self.absolute_to_coordinates(np.round(np.array(gt)[:, 1:], 0))\n",
    "        area_gt = (bb2[high]-bb2[low]).prod(-1)\n",
    "        indexes = self.number_of_detections(area_gt)\n",
    "\n",
    "        fn = np.sum(np.array([element*1 for element in indexes]), axis=1)\n",
    "        \n",
    "        return fn\n",
    "\n",
    "        \n",
    "#main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Image: 0, completion: 0.05%[[754. 397. 857. 531.]]\n",
      "[[761. 407. 851. 510.]]\n",
      "(1, 1)\n",
      " Image: 1, completion: 0.09%[[761. 386. 856. 519.]]\n",
      "[[762. 393. 847. 513.]]\n",
      "(1, 1)\n",
      " Image: 2, completion: 0.14%[[772. 390. 876. 516.]]\n",
      "[[783. 412. 866. 510.]]\n",
      "(1, 1)\n",
      " Image: 3, completion: 0.18%[[785. 383. 894. 523.]]\n",
      "[[788. 406. 881. 515.]]\n",
      "(1, 1)\n",
      " Image: 4, completion: 0.23%[[799. 386. 903. 546.]]\n",
      "[[802. 415. 895. 519.]]\n",
      "(1, 1)\n",
      " Image: 5, completion: 0.28%[[809. 399. 905. 535.]]\n",
      "[[813. 398. 899. 549.]]\n",
      "(1, 1)\n",
      " Image: 6, completion: 0.32%"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Sigurd\\OneDriveMS\\FYS-3741-MASTER\\Tensorflow\\workspace\\inference_tools\\evaluate_model.ipynb Cell 6'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sigurd/OneDriveMS/FYS-3741-MASTER/Tensorflow/workspace/inference_tools/evaluate_model.ipynb#ch0000005?line=26'>27</a>\u001b[0m txt \u001b[39m=\u001b[39m PRED[test_index]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sigurd/OneDriveMS/FYS-3741-MASTER/Tensorflow/workspace/inference_tools/evaluate_model.ipynb#ch0000005?line=28'>29</a>\u001b[0m file_number \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mfindall(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+\u001b[39m\u001b[39m'\u001b[39m, txt)[\u001b[39m0\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Sigurd/OneDriveMS/FYS-3741-MASTER/Tensorflow/workspace/inference_tools/evaluate_model.ipynb#ch0000005?line=30'>31</a>\u001b[0m test \u001b[39m=\u001b[39m EvaluationTools(gt_path \u001b[39m=\u001b[39;49m GT_PATH\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mLabel_images\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m+\u001b[39;49mfile_number\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.txt\u001b[39;49m\u001b[39m'\u001b[39;49m, im_path \u001b[39m=\u001b[39;49m IMAGE_PATH\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mLabel_images\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m+\u001b[39;49mfile_number\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.jpg\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sigurd/OneDriveMS/FYS-3741-MASTER/Tensorflow/workspace/inference_tools/evaluate_model.ipynb#ch0000005?line=31'>32</a>\u001b[0m                        pred_path\u001b[39m=\u001b[39;49mPRED_PATH\u001b[39m+\u001b[39;49mPRED[test_index], iou_threshold\u001b[39m=\u001b[39;49mTHRESH)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sigurd/OneDriveMS/FYS-3741-MASTER/Tensorflow/workspace/inference_tools/evaluate_model.ipynb#ch0000005?line=33'>34</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sigurd/OneDriveMS/FYS-3741-MASTER/Tensorflow/workspace/inference_tools/evaluate_model.ipynb#ch0000005?line=34'>35</a>\u001b[0m     pred, gt \u001b[39m=\u001b[39m test\u001b[39m.\u001b[39mget_bbox()\n",
      "\u001b[1;32mc:\\Users\\Sigurd\\OneDriveMS\\FYS-3741-MASTER\\Tensorflow\\workspace\\inference_tools\\evaluate_model.ipynb Cell 5'\u001b[0m in \u001b[0;36mEvaluationTools.__init__\u001b[1;34m(self, gt_path, im_path, pred_path, iou_threshold)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sigurd/OneDriveMS/FYS-3741-MASTER/Tensorflow/workspace/inference_tools/evaluate_model.ipynb#ch0000004?line=6'>7</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnames \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mclassification\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mh\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sigurd/OneDriveMS/FYS-3741-MASTER/Tensorflow/workspace/inference_tools/evaluate_model.ipynb#ch0000004?line=7'>8</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnames_pred \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mclassification\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mconfidence\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mh\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Sigurd/OneDriveMS/FYS-3741-MASTER/Tensorflow/workspace/inference_tools/evaluate_model.ipynb#ch0000004?line=9'>10</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mim_w, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mim_h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_image_info()\n",
      "\u001b[1;32mc:\\Users\\Sigurd\\OneDriveMS\\FYS-3741-MASTER\\Tensorflow\\workspace\\inference_tools\\evaluate_model.ipynb Cell 5'\u001b[0m in \u001b[0;36mEvaluationTools.get_image_info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sigurd/OneDriveMS/FYS-3741-MASTER/Tensorflow/workspace/inference_tools/evaluate_model.ipynb#ch0000004?line=68'>69</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_image_info\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sigurd/OneDriveMS/FYS-3741-MASTER/Tensorflow/workspace/inference_tools/evaluate_model.ipynb#ch0000004?line=69'>70</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sigurd/OneDriveMS/FYS-3741-MASTER/Tensorflow/workspace/inference_tools/evaluate_model.ipynb#ch0000004?line=70'>71</a>\u001b[0m \u001b[39m    Fetch image height and width\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sigurd/OneDriveMS/FYS-3741-MASTER/Tensorflow/workspace/inference_tools/evaluate_model.ipynb#ch0000004?line=71'>72</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Sigurd/OneDriveMS/FYS-3741-MASTER/Tensorflow/workspace/inference_tools/evaluate_model.ipynb#ch0000004?line=72'>73</a>\u001b[0m     im \u001b[39m=\u001b[39m load_image_to_numpy_array(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mim_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sigurd/OneDriveMS/FYS-3741-MASTER/Tensorflow/workspace/inference_tools/evaluate_model.ipynb#ch0000004?line=73'>74</a>\u001b[0m     im_w \u001b[39m=\u001b[39m im\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sigurd/OneDriveMS/FYS-3741-MASTER/Tensorflow/workspace/inference_tools/evaluate_model.ipynb#ch0000004?line=74'>75</a>\u001b[0m     im_h \u001b[39m=\u001b[39m im\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Sigurd\\OneDriveMS\\FYS-3741-MASTER\\Tensorflow\\workspace\\inference_tools\\src\\load_image.py:13\u001b[0m, in \u001b[0;36mload_image_to_numpy_array\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Sigurd/OneDriveMS/FYS-3741-MASTER/Tensorflow/workspace/inference_tools/src/load_image.py?line=10'>11</a>\u001b[0m image \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(BytesIO(img_data))\n\u001b[0;32m     <a href='file:///c%3A/Users/Sigurd/OneDriveMS/FYS-3741-MASTER/Tensorflow/workspace/inference_tools/src/load_image.py?line=11'>12</a>\u001b[0m (im_width, im_height) \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39msize\n\u001b[1;32m---> <a href='file:///c%3A/Users/Sigurd/OneDriveMS/FYS-3741-MASTER/Tensorflow/workspace/inference_tools/src/load_image.py?line=12'>13</a>\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49marray(image\u001b[39m.\u001b[39;49mgetdata())\u001b[39m.\u001b[39;49mreshape(im_height, im_width, \u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39muint8)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def recall(tp, fn):\n",
    "    return tp / (tp + fn + 1e-10)\n",
    "\n",
    "\n",
    "def precision(tp, fp):\n",
    "    return tp / (tp + fp + 1e-10)\n",
    "    \n",
    "\n",
    "#def main():\n",
    "TP = np.zeros(4)\n",
    "FP = np.zeros(4)\n",
    "FN = np.zeros(4)\n",
    "PRED_LARGE = 0\n",
    "PRED_MEDIUM = 0\n",
    "PRED_SMALL = 0\n",
    "PRED_TOTAL = 0\n",
    "THRESH = 0.1\n",
    "\n",
    "for test_index in range(len(PRED)):\n",
    "#for test_index in range(1115, 1120):\n",
    "    sys.stdout.write('\\r Image: {}, completion: {}%'.format(test_index, np.round((test_index + 1) / len(IM) * 100, 2)))\n",
    "    #for test_index in range(1):\n",
    "    #test_index = 4\n",
    "    #print(IMAGE_PATH+IM[test_index])\n",
    "    #print(GT_PATH+GT[test_index])\n",
    "    #print(PRED_PATH+PRED[test_index])\n",
    "    txt = PRED[test_index]\n",
    "\n",
    "    file_number = re.findall(r'\\d+', txt)[0]\n",
    "\n",
    "    test = EvaluationTools(gt_path = GT_PATH+'Label_images'+file_number+'.txt', im_path = IMAGE_PATH+'Label_images'+file_number+'.jpg',\n",
    "                           pred_path=PRED_PATH+PRED[test_index], iou_threshold=THRESH)\n",
    "\n",
    "    try:\n",
    "        pred, gt = test.get_bbox()\n",
    "        try:\n",
    "            iou, area_pred = test.get_iou(pred, gt)\n",
    "            area_indexes = test.number_of_detections(area_pred)\n",
    "            #n_tot = len(area_indexes)\n",
    "            #n_small = sum(area_indexes[1])\n",
    "\n",
    "            tp, fp, fn = test.find_valid_detections(iou, THRESH, area_indexes)\n",
    "        except:\n",
    "            print('Something is wrong with the TP/FP/FN calculation at index {}'.format(IM[test_index]))\n",
    "    except:\n",
    "        tp = np.zeros(4)\n",
    "        fp = np.zeros(4)\n",
    "        fn = test.no_predictions()\n",
    "        #print(fn)\n",
    "\n",
    "\n",
    "\n",
    "    TP += tp\n",
    "    FP += fp\n",
    "    FN += fn\n",
    "    sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:\n",
      "precision:  0.9987760097918972\n",
      "recall:  0.9772455089820125\n",
      "small:\n",
      "precision:  0.99999999995\n",
      "recall:  0.4999999999875\n",
      "medium:\n",
      "precision:  0.9959903769044911\n",
      "recall:  0.9394856278365401\n",
      "large:\n",
      "precision:  0.9999999999999647\n",
      "recall:  0.9954369954369605\n",
      "False Negatives: [total, small, medium, large]\n",
      "[95.  2. 80. 13.]\n",
      "False Positives: [total, small, medium, large]\n",
      "[5. 0. 5. 0.]\n",
      "True Positives: [total, small, medium, large]\n",
      "[4.080e+03 2.000e+00 1.242e+03 2.836e+03]\n"
     ]
    }
   ],
   "source": [
    "names = ['Total:', 'small:', 'medium:', 'large:']\n",
    "for i in range(TP.shape[0]):\n",
    "    print(names[i])\n",
    "    print('precision: ',precision(TP[i], FP[i]))\n",
    "    print('recall: ',recall(TP[i], FN[i]))\n",
    "\n",
    "print('False Negatives: [total, small, medium, large]')\n",
    "print(FN)\n",
    "print('False Positives: [total, small, medium, large]')\n",
    "print(FP)\n",
    "print('True Positives: [total, small, medium, large]')\n",
    "print(TP)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf925c25cf89ffabb2f3d88c1a5e71df6d5b95587e699ad6e5870eb2f2cce31d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
